{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4986a15c-bc9d-4813-974d-64e93c1476b1",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f453196-a351-4380-8691-5871e69b03a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mapping': {'<pad>': 0, '4': 1, '1': 2, 'c': 3, '[': 4, 'L': 5, 'S': 6, '5': 7, 'a': 8, 'l': 9, 'i': 10, '9': 11, '=': 12, 'r': 13, '3': 14, 'n': 15, 'O': 16, '(': 17, '\\\\': 18, 's': 19, 'o': 20, 'M': 21, ']': 22, 'B': 23, '2': 24, 'A': 25, '@': 26, '8': 27, '6': 28, '#': 29, 'g': 30, ')': 31, 'C': 32, 'I': 33, 'N': 34, 'H': 35, '0': 36, '-': 37, 'F': 38, '%': 39, '7': 40, '.': 41, '/': 42, 'P': 43, 'e': 44, 'K': 45, '+': 46, '[C@H]': 47, '[C@@H]': 48, '[nH]': 49, '[O-]': 50, '[C@]': 51, '[N+]': 52, '[C@@]': 53, '[S+]': 54, '<eos>': 55, '<sos>': 56}, 'inv_mapping': {0: '<pad>', 1: '4', 2: '1', 3: 'c', 4: '[', 5: 'L', 6: 'S', 7: '5', 8: 'a', 9: 'l', 10: 'i', 11: '9', 12: '=', 13: 'r', 14: '3', 15: 'n', 16: 'O', 17: '(', 18: '\\\\', 19: 's', 20: 'o', 21: 'M', 22: ']', 23: 'B', 24: '2', 25: 'A', 26: '@', 27: '8', 28: '6', 29: '#', 30: 'g', 31: ')', 32: 'C', 33: 'I', 34: 'N', 35: 'H', 36: '0', 37: '-', 38: 'F', 39: '%', 40: '7', 41: '.', 42: '/', 43: 'P', 44: 'e', 45: 'K', 46: '+', 47: '[C@H]', 48: '[C@@H]', 49: '[nH]', 50: '[O-]', 51: '[C@]', 52: '[N+]', 53: '[C@@]', 54: '[S+]', 55: '<eos>', 56: '<sos>'}, 'start_token': 56, 'end_token': 55, 'vocab_size': 57}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import TrainGAN\n",
    "from tokenizer import Tokenizer\n",
    "from layers import Generator, Discriminator\n",
    "\n",
    "# Load data\n",
    "data = []\n",
    "with open('filtered_smiles_dataset.csv', \"r\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        smile = line.strip()\n",
    "        data.append(smile)\n",
    "\n",
    "step = 340000\n",
    "\n",
    "# Define a function to read the top hyperparameters from the file\n",
    "def read_top_hyperparameters(file_path):\n",
    "    top_params = []\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            score, params = line.split(', Parameters: ')\n",
    "            params = eval(params.strip())\n",
    "            top_params.append(params)\n",
    "    return top_params\n",
    "\n",
    "# Read the top hyperparameters\n",
    "top_hyperparameters = read_top_hyperparameters(\"best_hyperparams.txt\")\n",
    "\n",
    "best_params_best = top_hyperparameters[0]\n",
    "hidden_dim_best = best_params_best['hidden_dim']\n",
    "lr_best = best_params_best['lr']\n",
    "dropout_best = best_params_best['dropout']\n",
    "batch_size_best = best_params_best['batch_size'] \n",
    "\n",
    "best_params_best\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "tokenizer_state = torch.load(f'models (final)/checkpoint_step_{step}/tokenizer.pth')\n",
    "print(tokenizer_state)\n",
    "tokenizer = Tokenizer(data)\n",
    "tokenizer.mapping = tokenizer_state['mapping']\n",
    "tokenizer.inv_mapping = tokenizer_state['inv_mapping']\n",
    "tokenizer.start_token = tokenizer_state['start_token']\n",
    "tokenizer.end_token = tokenizer_state['end_token']\n",
    "tokenizer.vocab_size = tokenizer_state['vocab_size']\n",
    "\n",
    "generator = Generator(\n",
    "    latent_dim=hidden_dim_best,\n",
    "    vocab_size=tokenizer.vocab_size - 1,\n",
    "    start_token=tokenizer.start_token - 1,\n",
    "    end_token=tokenizer.end_token - 1,\n",
    ").to(device)\n",
    "generator.load_state_dict(torch.load(f'models (final)/checkpoint_step_{step}/generator.pth'))\n",
    "\n",
    "discriminator = Discriminator(\n",
    "    hidden_size=hidden_dim_best,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    start_token=tokenizer.start_token,\n",
    "    bidirectional=True\n",
    ").to(device)\n",
    "discriminator.load_state_dict(torch.load(f'models (final)/checkpoint_step_{step}/discriminator.pth'))\n",
    "\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=lr_best)\n",
    "generator_optimizer.load_state_dict(torch.load(f'models (final)/checkpoint_step_{step}/generator_optimizer.pth'))\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=lr_best)\n",
    "discriminator_optimizer.load_state_dict(torch.load(f'models (final)/checkpoint_step_{step}/discriminator_optimizer.pth'))\n",
    "\n",
    "gan_model_loaded = TrainGAN(data, hidden_dim=hidden_dim_best, lr=lr_best, device=device)\n",
    "gan_model_loaded.tokenizer = tokenizer\n",
    "gan_model_loaded.generator = generator\n",
    "gan_model_loaded.discriminator = discriminator\n",
    "gan_model_loaded.generator_optim = generator_optimizer\n",
    "gan_model_loaded.discriminator_optim = discriminator_optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a95ba829-6ca5-4194-ad9a-ac075a1b5b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainGAN(\n",
       "  (generator): Generator(\n",
       "    (embedding_layer): Embedding(56, 256)\n",
       "    (project): FeedForward(\n",
       "      (_activations): ModuleList(\n",
       "        (0): LeakyReLU(negative_slope=0.01)\n",
       "        (1): ELU(alpha=0.1)\n",
       "      )\n",
       "      (_linear_layers): ModuleList(\n",
       "        (0): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "      )\n",
       "      (_dropout): ModuleList(\n",
       "        (0-1): 2 x Dropout(p=0.3, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (rnn): LSTMCell(256, 256)\n",
       "    (output_layer): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.01)\n",
       "      (1): Dropout(p=0.3, inplace=False)\n",
       "      (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.3, inplace=False)\n",
       "      (5): Linear(in_features=512, out_features=55, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (discriminator): Discriminator(\n",
       "    (embedding): Embedding(57, 256, padding_idx=0)\n",
       "    (rnn): LstmSeq2SeqEncoder(\n",
       "      (_module): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
       "    )\n",
       "    (fc): Sequential(\n",
       "      (0): LeakyReLU(negative_slope=0.01)\n",
       "      (1): Dropout(p=0.3, inplace=False)\n",
       "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Dropout(p=0.3, inplace=False)\n",
       "      (5): Linear(in_features=1024, out_features=1, bias=True)\n",
       "      (6): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan_model_loaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec43f51c-2491-46bc-98b9-6a816e738982",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles_list = gan_model_loaded.generate_n(150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ccb25c7-ce3d-4128-a758-6a41b02ae459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid:  141556\n",
      "invalid:  8444\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "data = []\n",
    "valid = 0\n",
    "invalid = 0\n",
    "\n",
    "def check_validity(smile):\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(smile)\n",
    "        if mol is not None:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "for smile in smiles_list:\n",
    "    if check_validity(smile):\n",
    "        validity = 'valid'\n",
    "        valid += 1\n",
    "    else:\n",
    "        validity = 'invalid'\n",
    "        invalid += 1\n",
    "    data.append([smile, validity])\n",
    "\n",
    "print(\"valid: \", valid)\n",
    "print(\"invalid: \", invalid)\n",
    "df = pd.DataFrame(data, columns=['canonical_smiles', 'validity'])\n",
    "df = df.drop_duplicates(subset=['canonical_smiles'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907b39ec-9351-4ed0-8d7f-fe9cb56c0a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>validity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O=C(NC1CCCCC1)c1nc2ccccc2s1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COc1ccc(/C=N/NC(=O)c2ccc(NC(=O)CC(=O)O)cc2)cc1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(NC1CCCCC1)Nc1ncc[nH]1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=[N+]([O-])c1ccc(-c2ccccc2)cc1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)c1ccccc1NC(=O)Nc1nccs1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149977</th>\n",
       "      <td>N#Cc1ccc([C@@H](O)C[C@@H](NC(=O)c2ccccc2)cc(Br...</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149979</th>\n",
       "      <td>COc1ccc(CNCC(=O)NCC(=O)O)c2ccccc21</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149980</th>\n",
       "      <td>CCOc1ccc(/C=N/NC(=O)c2ccc(Cl)cc2NC(=O)CCCCC2)cc1</td>\n",
       "      <td>invalid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149986</th>\n",
       "      <td>O=C(NCCOc1cccc(F)c1)c1ccc[nH]1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149988</th>\n",
       "      <td>N#CCCSc1nccs1</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30542 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         canonical_smiles validity\n",
       "0                             O=C(NC1CCCCC1)c1nc2ccccc2s1    valid\n",
       "1          COc1ccc(/C=N/NC(=O)c2ccc(NC(=O)CC(=O)O)cc2)cc1    valid\n",
       "2                               O=C(NC1CCCCC1)Nc1ncc[nH]1    valid\n",
       "3                         O=[N+]([O-])c1ccc(-c2ccccc2)cc1    valid\n",
       "4                          CCOC(=O)c1ccccc1NC(=O)Nc1nccs1    valid\n",
       "...                                                   ...      ...\n",
       "149977  N#Cc1ccc([C@@H](O)C[C@@H](NC(=O)c2ccccc2)cc(Br...  invalid\n",
       "149979                 COc1ccc(CNCC(=O)NCC(=O)O)c2ccccc21    valid\n",
       "149980   CCOc1ccc(/C=N/NC(=O)c2ccc(Cl)cc2NC(=O)CCCCC2)cc1  invalid\n",
       "149986                     O=C(NCCOc1cccc(F)c1)c1ccc[nH]1    valid\n",
       "149988                                      N#CCCSc1nccs1    valid\n",
       "\n",
       "[30542 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3223b4-825e-487b-b957-79abf168401b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('generated_molecules.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cdaaf1-b708-48ef-97c3-d61cd8586185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
